{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# VGG16 Cats vs Dogs (PyTorch, Colab-ready)\n",
        "\n",
        "é€™ä»½ Notebook æœƒï¼š\n",
        "1. å®‰è£å¿…è¦å¥—ä»¶\n",
        "2. æ›è¼‰ Google Drive\n",
        "3. ä½¿ç”¨ä½ åœ¨ Drive ä¸­çš„è³‡æ–™å¤¾çµæ§‹ `data/train|validation|test`\n",
        "4. ä»¥ VGG16ï¼ˆImageNet é è¨“ç·´ï¼‰è¨“ç·´ã€é©—è­‰ã€ï¼ˆå¯é¸ï¼‰æ¸¬è©¦\n",
        "5. å­˜ä¸‹æœ€ä½³æ¨¡å‹åˆ° `output_vgg16/best.pth`\n",
        "\n",
        "è³‡æ–™å¤¾çµæ§‹æ‡‰é•·é€™æ¨£ï¼š\n",
        "```\n",
        "data/\n",
        "â”œâ”€ train/\n",
        "â”‚  â”œâ”€ cats/\n",
        "â”‚  â””â”€ dogs/\n",
        "â”œâ”€ validation/\n",
        "â”‚  â”œâ”€ cats/\n",
        "â”‚  â””â”€ dogs/\n",
        "â””â”€ test/\n",
        "   â”œâ”€ cats/\n",
        "   â””â”€ dogs/\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {}
      },
      "outputs": [],
      "source": [
        "# å®‰è£ PyTorch èˆ‡ torchvisionï¼ˆColab é€šå¸¸å·²å…§å»ºï¼Œå¯è¦–æƒ…æ³é‡æ–°å®‰è£ï¼‰\n",
        "!pip -q install torch torchvision"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {}
      },
      "outputs": [],
      "source": [
        "# æ›è¼‰ Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# è¨­å®šä½ çš„è³‡æ–™æ ¹ç›®éŒ„ï¼ˆè«‹ç¢ºèªæ­¤è·¯å¾‘å­˜åœ¨ï¼‰\n",
        "DATA_ROOT = \"/content/drive/MyDrive/data\"  # â† å¦‚æœä½ çš„è³‡æ–™åœ¨å…¶ä»–è³‡æ–™å¤¾ï¼Œæ”¹é€™è¡Œ\n",
        "OUT_DIR   = \"/content/drive/MyDrive/output_vgg16\"  # æ¨¡å‹èˆ‡æ—¥èªŒè¼¸å‡ºä½ç½®\n",
        "IMG_SIZE = 224\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 10\n",
        "FREEZE_BACKBONE = True   # å…ˆå‡çµ VGG features å¾®èª¿åˆ†é¡å™¨ï¼›æƒ³å…¨è¨“ç·´å°±æ”¹ç‚º False\n",
        "USE_AMP = True           # å•Ÿç”¨æ··åˆç²¾åº¦ï¼ˆéœ€è¦ GPUï¼‰\n",
        "LR = 1e-4\n",
        "WEIGHT_DECAY = 1e-4\n",
        "DROPOUT_P = 0.5\n",
        "NUM_WORKERS = 2          # Colab å¯è¨­ 2~4ï¼›è‹¥é‡åˆ°å•é¡Œå¯è¨­ 0\n",
        "EARLY_STOP = 0           # >0 æ™‚å•Ÿç”¨ early stopï¼›ä¾‹å¦‚ 5\n",
        "MAX_GRAD_NORM = 0.0      # >0 å•Ÿç”¨æ¢¯åº¦è£åˆ‡\n",
        "SEED = 42"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ğŸ”§ æ ¸å¿ƒè¨“ç·´èˆ‡è©•ä¼°ç¨‹å¼ï¼ˆç­‰åŒæ–¼å‰é¢çµ¦ä½ çš„ train_vgg16_catsdogs.py çš„åŠŸèƒ½ï¼‰\n",
        "import os\n",
        "import random\n",
        "import time\n",
        "from pathlib import Path\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from torchvision import datasets, transforms, models\n",
        "\n",
        "def set_seed(seed: int):\n",
        "    random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "def build_transforms(img_size: int):\n",
        "    imagenet_mean = [0.485, 0.456, 0.406]\n",
        "    imagenet_std  = [0.229, 0.224, 0.225]\n",
        "    train_tf = transforms.Compose([\n",
        "        transforms.Resize(int(img_size * 1.15)),\n",
        "        transforms.RandomResizedCrop(img_size),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(imagenet_mean, imagenet_std),\n",
        "    ])\n",
        "    eval_tf = transforms.Compose([\n",
        "        transforms.Resize(int(img_size * 1.15)),\n",
        "        transforms.CenterCrop(img_size),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(imagenet_mean, imagenet_std),\n",
        "    ])\n",
        "    return train_tf, eval_tf\n",
        "\n",
        "def create_dataloaders_with_val(data_root: str, img_size: int, batch_size: int,\n",
        "                               num_workers: int, seed: int):\n",
        "    # å°ˆç‚ºå·²å­˜åœ¨ train/ validation/ test/ çš„çµæ§‹\n",
        "    train_tf, eval_tf = build_transforms(img_size)\n",
        "    root = Path(data_root)\n",
        "    train_ds = datasets.ImageFolder(root / \"train\", transform=train_tf)\n",
        "    val_ds   = datasets.ImageFolder(root / \"validation\", transform=eval_tf)\n",
        "    test_ds  = None\n",
        "    if (root / \"test\").exists():\n",
        "        test_ds = datasets.ImageFolder(root / \"test\", transform=eval_tf)\n",
        "    class_names = train_ds.classes\n",
        "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True,\n",
        "                              num_workers=num_workers, pin_memory=True)\n",
        "    val_loader = DataLoader(val_ds, batch_size=batch_size, shuffle=False,\n",
        "                            num_workers=num_workers, pin_memory=True)\n",
        "    test_loader = None\n",
        "    if test_ds is not None:\n",
        "        test_loader = DataLoader(test_ds, batch_size=batch_size, shuffle=False,\n",
        "                                 num_workers=num_workers, pin_memory=True)\n",
        "    return train_loader, val_loader, test_loader, class_names\n",
        "\n",
        "def build_model(num_classes: int, freeze_backbone: bool, dropout_p: float):\n",
        "    vgg = models.vgg16(weights=models.VGG16_Weights.IMAGENET1K_V1)\n",
        "    if freeze_backbone:\n",
        "        for p in vgg.features.parameters():\n",
        "            p.requires_grad = False\n",
        "    in_features = vgg.classifier[6].in_features\n",
        "    new_classifier = list(vgg.classifier)\n",
        "    if isinstance(new_classifier[5], nn.Dropout):\n",
        "        new_classifier[5] = nn.Dropout(p=dropout_p)\n",
        "    new_classifier[6] = nn.Linear(in_features, num_classes)\n",
        "    vgg.classifier = nn.Sequential(*new_classifier)\n",
        "    return vgg\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluate(model, loader, device):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    num_classes = model.classifier[-1].out_features\n",
        "    cm = torch.zeros((num_classes, num_classes), dtype=torch.long)\n",
        "    for images, labels in loader:\n",
        "        images = images.to(device, non_blocking=True)\n",
        "        labels = labels.to(device, non_blocking=True)\n",
        "        logits = model(images)\n",
        "        preds = logits.argmax(dim=1)\n",
        "        correct += (preds == labels).sum().item()\n",
        "        total += labels.size(0)\n",
        "        for t, p in zip(labels.view(-1), preds.view(-1)):\n",
        "            cm[t.long(), p.long()] += 1\n",
        "    acc = correct / max(total, 1)\n",
        "    return acc, cm\n",
        "\n",
        "def save_checkpoint(state: dict, is_best: bool, out_dir: str):\n",
        "    out = Path(out_dir)\n",
        "    out.mkdir(parents=True, exist_ok=True)\n",
        "    torch.save(state, out / \"last.pth\")\n",
        "    if is_best:\n",
        "        torch.save(state, out / \"best.pth\")\n",
        "\n",
        "def export_onnx(model, device, img_size, num_classes, out_path: Path):\n",
        "    model.eval()\n",
        "    dummy = torch.randn(1, 3, img_size, img_size, device=device)\n",
        "    dynamic_axes = {\"input\": {0: \"batch\"}, \"logits\": {0: \"batch\"}}\n",
        "    torch.onnx.export(model, dummy, str(out_path),\n",
        "                      input_names=[\"input\"], output_names=[\"logits\"],\n",
        "                      dynamic_axes=dynamic_axes, opset_version=12)\n",
        "    print(f\"[Export] ONNX -> {out_path}\")\n",
        "\n",
        "def export_torchscript(model, device, out_path: Path):\n",
        "    model.eval()\n",
        "    scripted = torch.jit.script(model)\n",
        "    scripted.save(str(out_path))\n",
        "    print(f\"[Export] TorchScript -> {out_path}\")\n",
        "\n",
        "@torch.no_grad()\n",
        "def predict_image(model_path: str, image_path: str, img_size: int = 224, cpu: bool = False):\n",
        "    device = torch.device(\"cpu\" if cpu or not torch.cuda.is_available() else \"cuda\")\n",
        "    ckpt = torch.load(model_path, map_location=device)\n",
        "    class_names = ckpt[\"class_names\"]\n",
        "    model = build_model(num_classes=len(class_names), freeze_backbone=False, dropout_p=0.5)\n",
        "    model.load_state_dict(ckpt[\"state_dict\"])\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "    _, eval_tf = build_transforms(img_size)\n",
        "    from PIL import Image\n",
        "    img = Image.open(image_path).convert(\"RGB\")\n",
        "    x = eval_tf(img).unsqueeze(0).to(device)\n",
        "    logits = model(x)\n",
        "    probs = torch.softmax(logits, dim=1)[0]\n",
        "    pred_idx = int(torch.argmax(probs).item())\n",
        "    return class_names[pred_idx], float(probs[pred_idx].item())\n",
        "\n",
        "def train_loop(data_root: str, out_dir: str, img_size: int, batch_size: int, epochs: int,\n",
        "               freeze_backbone: bool, amp: bool, lr: float, weight_decay: float,\n",
        "               dropout: float, workers: int, early_stop: int, max_grad_norm: float, seed: int):\n",
        "    set_seed(seed)\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(f\"[Device] {device}\")\n",
        "    train_loader, val_loader, test_loader, class_names = create_dataloaders_with_val(\n",
        "        data_root=data_root, img_size=img_size, batch_size=batch_size,\n",
        "        num_workers=workers, seed=seed\n",
        "    )\n",
        "    print(f\"[Classes] {class_names}\")\n",
        "    model = build_model(num_classes=len(class_names), freeze_backbone=freeze_backbone, dropout_p=dropout)\n",
        "    model.to(device)\n",
        "    params = [p for p in model.parameters() if p.requires_grad]\n",
        "    optimizer = optim.AdamW(params, lr=lr, weight_decay=weight_decay)\n",
        "    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    scaler = torch.cuda.amp.GradScaler(enabled=(device.type == \"cuda\" and amp))\n",
        "    best_acc = 0.0\n",
        "    epochs_no_improve = 0\n",
        "    since = time.time()\n",
        "    for epoch in range(1, epochs + 1):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        running_correct = 0\n",
        "        running_total = 0\n",
        "        for images, labels in train_loader:\n",
        "            images = images.to(device, non_blocking=True)\n",
        "            labels = labels.to(device, non_blocking=True)\n",
        "            optimizer.zero_grad(set_to_none=True)\n",
        "            with torch.cuda.amp.autocast(enabled=(device.type == \"cuda\" and amp)):\n",
        "                logits = model(images)\n",
        "                loss = criterion(logits, labels)\n",
        "            scaler.scale(loss).backward()\n",
        "            if max_grad_norm is not None and max_grad_norm > 0:\n",
        "                scaler.unscale_(optimizer)\n",
        "                torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "            running_loss += loss.item() * labels.size(0)\n",
        "            preds = logits.argmax(dim=1)\n",
        "            running_correct += (preds == labels).sum().item()\n",
        "            running_total += labels.size(0)\n",
        "        train_loss = running_loss / max(running_total, 1)\n",
        "        train_acc = running_correct / max(running_total, 1)\n",
        "        val_acc, val_cm = evaluate(model, val_loader, device)\n",
        "        scheduler.step()\n",
        "        is_best = val_acc > best_acc\n",
        "        if is_best:\n",
        "            best_acc = val_acc\n",
        "            epochs_no_improve = 0\n",
        "        else:\n",
        "            epochs_no_improve += 1\n",
        "        save_checkpoint({\n",
        "            \"epoch\": epoch,\n",
        "            \"state_dict\": model.state_dict(),\n",
        "            \"optimizer\": optimizer.state_dict(),\n",
        "            \"scheduler\": scheduler.state_dict(),\n",
        "            \"best_acc\": best_acc,\n",
        "            \"class_names\": class_names,\n",
        "            \"args\": {\n",
        "                \"img_size\": img_size, \"batch_size\": batch_size, \"epochs\": epochs,\n",
        "                \"freeze_backbone\": freeze_backbone, \"amp\": amp, \"lr\": lr,\n",
        "                \"weight_decay\": weight_decay, \"dropout\": dropout, \"workers\": workers,\n",
        "                \"early_stop\": early_stop, \"max_grad_norm\": max_grad_norm, \"seed\": seed\n",
        "            }\n",
        "        }, is_best=is_best, out_dir=out_dir)\n",
        "        print(f\"[Epoch {epoch:03d}/{epochs}] train_loss={train_loss:.4f} train_acc={train_acc:.4f} val_acc={val_acc:.4f} best_val_acc={best_acc:.4f}\")\n",
        "        if early_stop > 0 and epochs_no_improve >= early_stop:\n",
        "            print(f\"[EarlyStop] No improvement for {early_stop} epochs.\")\n",
        "            break\n",
        "    elapsed = time.time() - since\n",
        "    print(f\"[Done] Time: {elapsed/60.0:.1f} min, Best Val Acc: {best_acc:.4f}\")\n",
        "    if (Path(out_dir) / \"best.pth\").exists() and (Path(DATA_ROOT) / \"test\").exists():\n",
        "        best_ckpt = torch.load(Path(out_dir) / \"best.pth\", map_location=device)\n",
        "        model.load_state_dict(best_ckpt[\"state_dict\"])\n",
        "        test_loader = DataLoader(datasets.ImageFolder(Path(DATA_ROOT)/\"test\", transform=build_transforms(img_size)[1]),\n",
        "                                 batch_size=batch_size, shuffle=False, num_workers=workers, pin_memory=True)\n",
        "        test_acc, test_cm = evaluate(model, test_loader, device)\n",
        "        print(f\"[Test] acc={test_acc:.4f}\")\n",
        "        print(\"[Test] Confusion Matrix (rows=true, cols=pred):\")\n",
        "        print(test_cm.cpu().numpy())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# â–¶ï¸ é–‹å§‹è¨“ç·´\n",
        "train_loop(\n",
        "    data_root=DATA_ROOT,\n",
        "    out_dir=OUT_DIR,\n",
        "    img_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    epochs=EPOCHS,\n",
        "    freeze_backbone=FREEZE_BACKBONE,\n",
        "    amp=USE_AMP,\n",
        "    lr=LR,\n",
        "    weight_decay=WEIGHT_DECAY,\n",
        "    dropout=DROPOUT_P,\n",
        "    workers=NUM_WORKERS,\n",
        "    early_stop=EARLY_STOP,\n",
        "    max_grad_norm=MAX_GRAD_NORM,\n",
        "    seed=SEED,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## æ¨è«–ï¼ˆå–®å¼µåœ–ç‰‡ï¼‰\n",
        "æŠŠ `IMAGE_PATH` æŒ‡å‘ä½ çš„æ¸¬è©¦å½±åƒï¼Œä¾‹å¦‚ï¼š\n",
        "`/content/drive/MyDrive/data/test/cats/xxx.jpg`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "IMAGE_PATH = \"/content/drive/MyDrive/data/test/cats/your_image.jpg\"  # â† æ”¹æˆä½ çš„åœ–ç‰‡è·¯å¾‘\n",
        "MODEL_PATH = str(Path(OUT_DIR) / \"best.pth\")\n",
        "if Path(MODEL_PATH).exists() and Path(IMAGE_PATH).exists():\n",
        "    pred, prob = predict_image(MODEL_PATH, IMAGE_PATH, img_size=IMG_SIZE, cpu=False)\n",
        "    print(f\"Predicted: {pred} ({prob:.3f})\")\n",
        "else:\n",
        "    print(\"è«‹å…ˆç¢ºèª MODEL_PATH èˆ‡ IMAGE_PATH æ˜¯å¦å­˜åœ¨ï¼š\\n\", MODEL_PATH, \"\\n\", IMAGE_PATH)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "### å‚™è¨»\n",
        "- è‹¥é‡åˆ° DataLoader å•é¡Œï¼Œå¯æŠŠ `NUM_WORKERS` è¨­ç‚º 0ã€‚\n",
        "- æƒ³è¦å…¨ç¶²è·¯ä¸€èµ·è¨“ç·´ï¼Œè«‹æŠŠ `FREEZE_BACKBONE=False`ï¼Œä¸¦å¯æŠŠ `LR` ç¨å¾®èª¿å°ä¸€é»å†å¤šè¨“ç·´ã€‚\n",
        "- é€™ä»½ Notebook ä¹Ÿæ”¯æ´ ONNX/TorchScript åŒ¯å‡ºï¼ˆæœ‰å°æ‡‰å‡½å¼ï¼‰ï¼Œä½ å¯ä»¥è‡ªè¡Œå‘¼å« `export_onnx` æˆ– `export_torchscript`ã€‚"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "VGG16_CatsDogs_Colab.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}